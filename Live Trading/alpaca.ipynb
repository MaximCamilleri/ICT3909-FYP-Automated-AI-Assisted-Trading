{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpaca Paper Trading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../FinRL/\")\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import alpaca_trade_api as tradeapi\n",
    "from alpaca_trade_api.rest import TimeFrame\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import threading\n",
    "import pickle\n",
    "from stable_baselines3 import A2C\n",
    "import yfinance as yf\n",
    "import itertools\n",
    "from datetime import date, timedelta\n",
    "import datetime\n",
    "from stockstats import StockDataFrame as Sdf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from copy import deepcopy\n",
    "import empyrical\n",
    "from contextlib import contextmanager\n",
    "import sys, os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FinRL Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.plot import get_daily_return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finrl.config import INDICATORS, TRAINED_MODEL_DIR\n",
    "from Config.alpacha_config import API_KEY, API_SECRET, API_BASE_URL\n",
    "from Config.local_config import PCA_INDICATORS\n",
    "from Config.local_config import DOW_30_TICKERS\n",
    "import Config.model_kwargs_config as model_kwargs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regime Switching "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def suppress_stdout():\n",
    "    with open(os.devnull, \"w\") as devnull:\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = devnull\n",
    "        try:  \n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_parameters:\n",
    "    def __init__(self, model_name, kwargs, steps, data, data_retention_level):\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self.sharpe = []\n",
    "        self.kwargs = kwargs\n",
    "        self.policy = \"MlpPolicy\"\n",
    "        self.policy_kwargs = None\n",
    "        self.verbose = 0\n",
    "        self.total_timesteps = steps\n",
    "        self.data = data\n",
    "        self.data_retention_level = data_retention_level"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class run_PCA():\n",
    "    def __init__(self, indicators, data, tickers) -> None:\n",
    "        self.data = data\n",
    "        self.tickers = tickers\n",
    "        self.indicators = indicators\n",
    "        self.number_of_components = -1\n",
    "    \n",
    "    def run_PCA(self, n_components = .99):\n",
    "        x = self.data.loc[:, self.indicators].values\n",
    "        x = StandardScaler().fit_transform(x)\n",
    "        pca = PCA(n_components=n_components)\n",
    "\n",
    "        principalComponents = pca.fit_transform(x)\n",
    "        principalDf = pd.DataFrame(data = principalComponents)\n",
    "\n",
    "        pickle.dump(pca, open(f\"PCA_models/PCA_Model_{str(n_components)}.pickle\", 'wb'))\n",
    "\n",
    "        ret = self.data[['date','tic','open','high','low','close','volume', 'day']]\n",
    "\n",
    "        for count in range(0, len(principalDf.columns)):\n",
    "            ret[count] = principalDf[count].values\n",
    "\n",
    "        ret['vix'] = self.data['vix']\n",
    "        ret['turbulence'] = self.data['turbulence']\n",
    "        \n",
    "        self.number_of_components = len(principalDf.columns)\n",
    "\n",
    "        ret = ret.fillna(0)\n",
    "\n",
    "        # ConfusionMatrixDisplay.from_estimator(\n",
    "        #     principalComponents, display_labels = self.indicators, xticks_rotation = \"vertical\"\n",
    "        # )\n",
    "\n",
    "        return ret\n",
    "\n",
    "class data_preparation:\n",
    "    def __init__(self, start_date, end_date, tickers, indicators) -> None:\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.tickers = tickers\n",
    "        self.indicators = indicators\n",
    "\n",
    "        self.data = YahooDownloader(start_date = self.start_date,\n",
    "                                    end_date = self.end_date,\n",
    "                                    ticker_list = tickers).fetch_data()\n",
    "        self.data.sort_values(['date', 'tic'], ignore_index = True)\n",
    "        \n",
    "\n",
    "    def add_indicators(self, vix:bool, turbulence:bool):\n",
    "        fe = FeatureEngineer(\n",
    "            use_technical_indicator = True,\n",
    "            tech_indicator_list = self.indicators, \n",
    "            use_vix = vix, # a real time market index representing the markets expectations for volatility over the next 30 days\n",
    "            use_turbulence = True, # accounts for unexpected rising and falling of the stock market\n",
    "            user_defined_feature = False)\n",
    "\n",
    "        processed = fe.preprocess_data(self.data)\n",
    "        \n",
    "        list_ticker = processed[\"tic\"].unique().tolist()\n",
    "        list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "        combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "        processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "        processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "        processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "        self.data = processed_full.fillna(0)\n",
    "    \n",
    "    def add_pca(self, vix, turbulence, n_components):\n",
    "        self.add_indicators(vix, turbulence)\n",
    "        self.pca = run_PCA(self.indicators, self.data, self.tickers)\n",
    "        self.data = self.pca.run_PCA(n_components)\n",
    "    \n",
    "    def save_data(self, name):\n",
    "        self.data.to_csv(f\"../Datasets/{name}.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regime Switching Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class regime_switching():\n",
    "    def __init__(self, start_date, model_names, account_in):\n",
    "        self.rebalance_time = 0\n",
    "        self.training_start_date = start_date\n",
    "        self.model_names = model_names\n",
    "        self.account = account_in\n",
    "\n",
    "        with suppress_stdout():\n",
    "            self.update_data()\n",
    "\n",
    "        self.model_kwargs_dict = {\n",
    "            \"a2c\": model_kwargs.A2C_KWARGS,\n",
    "            \"ppo\": model_kwargs.PPO_KWARGS,\n",
    "            \"sac\": model_kwargs.SAC_KWARGS,\n",
    "            \"td3\": model_kwargs.TD3_KWARGS,\n",
    "            \"ddpg\": model_kwargs.DDPG_KWARGS\n",
    "        }\n",
    "\n",
    "        self.create_alg_variations()\n",
    "\n",
    "    def run_regime_switching(self):\n",
    "        unique_train_dates = self.algs[0].data[\n",
    "            (self.algs[0].data.date < self.todays_date)\n",
    "        ].date.unique()\n",
    "        \n",
    "\n",
    "        for model_params in self.algs:\n",
    "            training_env, e_val_gym = self.create_environments(unique_train_dates[-63], model_params.data)\n",
    "            print(f\"Training {model_params.model_name}_{model_params.data_retention_level}\")\n",
    "            trained_model = self.train_algs(training_env, model_params)\n",
    "            model_params.model = trained_model\n",
    "            model_params.sharpe.append(self.val_algs(e_val_gym, trained_model))\n",
    "        \n",
    "        best_model = self.select_best_model()\n",
    "\n",
    "        return best_model\n",
    "\n",
    "    def update_data(self):\n",
    "        self.todays_date = datetime.today().strftime('%Y-%m-%d')\n",
    "        self.data_85 = self.get_data(0.85)\n",
    "        self.data_99 = self.get_data(0.99)\n",
    "    \n",
    "    def get_data(self, n_components):\n",
    "        pcaData = data_preparation(self.training_start_date, self.todays_date, DOW_30_TICKERS, PCA_INDICATORS)\n",
    "        pcaData.add_pca(vix=True, turbulence=True, n_components = n_components)\n",
    "\n",
    "        return pcaData.data\n",
    "    \n",
    "    def create_alg_variations(self):\n",
    "        self.algs = []\n",
    "        for name in self.model_names:\n",
    "            self.algs.append(model_parameters(model_name = name,\n",
    "                                              kwargs = deepcopy(self.model_kwargs_dict[name]),\n",
    "                                              steps = deepcopy(model_kwargs.TIMESTEPS_DICT[name]),\n",
    "                                              data = self.data_85,\n",
    "                                              data_retention_level = \"85\"))\n",
    "            self.algs.append(model_parameters(model_name = name,\n",
    "                                              kwargs = deepcopy(self.model_kwargs_dict[name]),\n",
    "                                              steps = deepcopy(model_kwargs.TIMESTEPS_DICT[name]),\n",
    "                                              data = self.data_99,\n",
    "                                              data_retention_level = \"99\"))\n",
    "    \n",
    "    def create_environments(self, train_end, data):\n",
    "        train_data = data_split(\n",
    "            data,\n",
    "            start = self.training_start_date,\n",
    "            end = train_end\n",
    "        )\n",
    "\n",
    "        val_data = data_split(\n",
    "            data,\n",
    "            start = train_end,\n",
    "            end = self.todays_date\n",
    "        )\n",
    "\n",
    "        kwargs = {\n",
    "            'hmax': self.account.hmax,\n",
    "            \"initial_amount\": self.account.cash,\n",
    "            \"num_stock_shares\": [0] * self.account.stock_dimension,\n",
    "            \"buy_cost_pct\": self.account.buy_cost_list,\n",
    "            \"sell_cost_pct\": self.account.sell_cost_list,\n",
    "            \"state_space\": 1 + 2 * self.account.stock_dimension + len(train_data.columns[7:-2]) * self.account.stock_dimension,\n",
    "            \"stock_dim\": self.account.stock_dimension,\n",
    "            \"tech_indicator_list\": train_data.columns[7:-2],\n",
    "            \"action_space\": self.account.stock_dimension,\n",
    "            \"reward_scaling\": 1e-4\n",
    "        }\n",
    "\n",
    "        e_train_gym = StockTradingEnv(df = train_data, **kwargs)\n",
    "        e_val_gym = StockTradingEnv(df = val_data, turbulence_threshold = 30, risk_indicator_col='vix', **kwargs)\n",
    "\n",
    "        training_env, _ = e_train_gym.get_sb_env()\n",
    "\n",
    "        return training_env, e_val_gym\n",
    "    \n",
    "    def train_algs(self, training_env, model_params):\n",
    "        with suppress_stdout():\n",
    "            agent = DRLAgent(env = training_env)\n",
    "            model = agent.get_model(\n",
    "                model_params.model_name,\n",
    "                policy = model_params.policy,\n",
    "                policy_kwargs = model_params.policy_kwargs,\n",
    "                model_kwargs = model_params.kwargs\n",
    "            )\n",
    "            trained_model = agent.train_model(model = model, tb_log_name = model_params.model_name, total_timesteps = model_params.total_timesteps)\n",
    "\n",
    "        return trained_model\n",
    "\n",
    "    def val_algs(self, e_val_env, trained_model):\n",
    "        with suppress_stdout():\n",
    "            df_account_value, df_actions, _ = DRLAgent.DRL_prediction(\n",
    "                model = trained_model, \n",
    "                environment = e_val_env\n",
    "            )\n",
    "\n",
    "        df = deepcopy(df_account_value)\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        bt_returns = get_daily_return(df, value_col_name=\"account_value\")\n",
    "\n",
    "        return empyrical.sharpe_ratio(bt_returns)\n",
    "\n",
    "    def select_best_model(self):\n",
    "        best_model_sharpe = float('-inf')\n",
    "        for model in self.algs:\n",
    "            if model.sharpe[-1] > best_model_sharpe:\n",
    "                best_model_sharpe = model.sharpe[-1]\n",
    "                best_model = model\n",
    "                best_model_name = model.model_name\n",
    "        \n",
    "        return best_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpaca Trading\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class account():\n",
    "    def __init__(self, ticker_list, cash, num_stock_shares):\n",
    "        stock_dimension = len(ticker_list)\n",
    "        self.cash = cash\n",
    "        self.ticker_list = ticker_list\n",
    "        self.num_stock_shares = num_stock_shares\n",
    "        self.buy_cost_list = [0.001] * stock_dimension\n",
    "        self.sell_cost_list = [0.001] * stock_dimension\n",
    "        self.stock_dimension = stock_dimension\n",
    "        self.hmax = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Live Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetData:\n",
    "    def __init__(self, time_interval, alpaca, tech_indicator_list, PCA_path):\n",
    "        self.time_interval = time_interval\n",
    "        self.alpaca = alpaca\n",
    "        self.tech_indicator_list = tech_indicator_list\n",
    "        self.PCA_path = PCA_path\n",
    "\n",
    "        # PCA\n",
    "        if self.PCA_path != None:\n",
    "            with open(self.PCA_path, 'rb') as fp:\n",
    "                self.PCA_model = pickle.load(fp)\n",
    "    \n",
    "    def download_live_data(self):\n",
    "        print(\"Fetching updated data...\")\n",
    "        data_df = pd.DataFrame()\n",
    "\n",
    "        # ========= Getting Data Using Alpaca =========\n",
    "        if self.time_interval == TimeFrame.Day:\n",
    "            days = 60\n",
    "        else:\n",
    "            days = 5\n",
    "            \n",
    "        for tic in DOW_30_TICKERS:\n",
    "            df = self.alpaca.get_bars(\n",
    "                symbol=tic,\n",
    "                start=datetime.date.today() - datetime.timedelta(days = 300),\n",
    "                timeframe=self.time_interval,\n",
    "                adjustment=\"raw\",\n",
    "            ).df.tz_convert(\"US/Eastern\").tail(300)\n",
    "            df[\"tic\"] = tic\n",
    "            data_df = pd.concat([data_df, df])\n",
    "        data_df = data_df.reset_index()\n",
    "\n",
    "        # ========= Adding Technical Indicators =========\n",
    "        data_df[\"day\"] = data_df[\"timestamp\"].dt.dayofweek\n",
    "        data_df = data_df.dropna()\n",
    "        data_df = data_df.reset_index(drop=True)\n",
    "        data_df[\"timestamp\"] = data_df.timestamp.apply(lambda x: x.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        data_df = data_df.sort_values(by=[\"timestamp\", \"tic\"]).reset_index(drop=True)\n",
    "        df = self.add_technical_indicator(data_df)\n",
    "        df = df.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "\n",
    "        # ========= Calculating Turbulence =========\n",
    "        turb_df = self.alpaca.get_bars(\n",
    "            symbol=\"VIXY\",\n",
    "            start=datetime.date.today() - datetime.timedelta(days = 1),\n",
    "            timeframe=self.time_interval,\n",
    "            adjustment=\"raw\",\n",
    "        ).df.tz_convert(\"US/Eastern\").tail(1)\n",
    "        latest_turb = turb_df[\"close\"].values\n",
    "\n",
    "        # ========= Applying PCA =========\n",
    "        if self.PCA_path != None:\n",
    "            df = df.reset_index(drop=True)\n",
    "            x = df.loc[:, PCA_INDICATORS].values\n",
    "            x = StandardScaler().fit_transform(x)\n",
    "            new = self.PCA_model.transform(x)\n",
    "            principalDf = pd.DataFrame(data = new)\n",
    "\n",
    "            ret = df[['date','tic','open','high','low','close','volume', 'day']]\n",
    "            for count in range(0, len(principalDf.columns)):\n",
    "                ret[count] = principalDf[count].values\n",
    "            self.number_of_pca_comps = len(principalDf.columns)\n",
    "            df = ret\n",
    "            \n",
    "        # ========= Data Formatting =========\n",
    "        start_date = df[\"date\"].iloc[0]\n",
    "        end_date = df[\"date\"].iloc[-1]\n",
    "        # print(\"start: \", start_date)\n",
    "        # print(\"start: \", end_date)\n",
    "        data = data_split(df, start_date, end_date)\n",
    "        data = data[data.index == data.index.unique()[-1]]\n",
    "        print(f\"Retrieved data for timestamp: {data['date'].unique()[0]}\")\n",
    "\n",
    "        return data, latest_turb[0]\n",
    "\n",
    "    def add_technical_indicator(self, df):\n",
    "        df = df.rename(columns={\"timestamp\": \"date\"})\n",
    "        df = df.copy()\n",
    "        df = df.sort_values(by=[\"tic\", \"date\"])\n",
    "        \n",
    "        stock = Sdf.retype(df.copy())\n",
    "        unique_ticker = stock.tic.unique()\n",
    "        tech_indicator_list = self.tech_indicator_list\n",
    "\n",
    "        for indicator in tech_indicator_list:\n",
    "            indicator_df = pd.DataFrame()\n",
    "            for i in range(len(unique_ticker)):\n",
    "                # print(unique_ticker[i], i)\n",
    "                temp_indicator = stock[stock.tic == unique_ticker[i]][indicator]\n",
    "                temp_indicator = pd.DataFrame(temp_indicator)\n",
    "                temp_indicator[\"tic\"] = unique_ticker[i]\n",
    "                # print(len(df[df.tic == unique_ticker[i]]['date'].to_list()))\n",
    "                temp_indicator[\"date\"] = df[df.tic == unique_ticker[i]][\"date\"].to_list()\n",
    "                indicator_df = pd.concat(\n",
    "                    [indicator_df, temp_indicator], ignore_index=True\n",
    "                )\n",
    "            df = df.merge(\n",
    "                indicator_df[[\"tic\", \"date\", indicator]], on=[\"tic\", \"date\"], how=\"left\"\n",
    "            )\n",
    "        df = df.sort_values(by=[\"date\", \"tic\"])\n",
    "        return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlpacaPaperTrading():\n",
    "    def __init__(self, ticker_list, time_interval, API_KEY, API_SECRET, API_BASE_URL, tech_indicator_list, turbulence_thresh = 30, \n",
    "                 latency = None, sell_at_end_of_day = False, pca_path = None):\n",
    "        \n",
    "        self.sell_at_end_of_day = sell_at_end_of_day\n",
    "        self.pca_path = pca_path\n",
    "        self.rebalance_counter = 0\n",
    "\n",
    "        # Alpaca\n",
    "        self.API_KEY = API_KEY\n",
    "        self.API_BASE_URL = API_BASE_URL\n",
    "        self.API_SECRET = API_SECRET\n",
    "        self.AlpacaConnection()\n",
    "\n",
    "        # Account\n",
    "        num_stock_shares = [0] * len(ticker_list)\n",
    "        for tic in range(len(ticker_list)):\n",
    "            try:\n",
    "                num_stock_shares[tic] = self.alpaca.get_position(ticker_list[tic]).qty_available\n",
    "            except:\n",
    "                num_stock_shares[tic] = 0\n",
    "\n",
    "        self.account = account(ticker_list, float(self.alpaca.get_account().cash), num_stock_shares)\n",
    "        \n",
    "        # Getting Data\n",
    "        self.data_retrieve = GetData(time_interval, self.alpaca, tech_indicator_list, pca_path)\n",
    "\n",
    "        # Trading Settings\n",
    "        self.tech_indicator_list = tech_indicator_list\n",
    "        self.turbulence_thresh = turbulence_thresh\n",
    "        self.time_interval = time_interval\n",
    "        self.sell_time = 60\n",
    "\n",
    "        # Sleep time \n",
    "        if time_interval == TimeFrame.Day:\n",
    "            self.sleep_time = 86400 * time_interval.amount\n",
    "        elif time_interval == TimeFrame.Hour:\n",
    "            self.sleep_time = 3600 * time_interval.amount\n",
    "        elif time_interval == TimeFrame.Minute:\n",
    "            self.sleep_time = 60 * time_interval.amount\n",
    "        \n",
    "    def AlpacaConnection(self):\n",
    "        try:\n",
    "            self.alpaca = tradeapi.REST(self.API_KEY, self.API_SECRET, self.API_BASE_URL, 'v2')\n",
    "        except:\n",
    "            raise ValueError('Fail to connect Alpaca. Please check account info and internet connection')\n",
    "    \n",
    "    def awaitMarketOpen(self):\n",
    "        isOpen = self.alpaca.get_clock().is_open\n",
    "        while(not isOpen):\n",
    "            clock = self.alpaca.get_clock()\n",
    "            openingTime = clock.next_open.replace(tzinfo=datetime.timezone.utc).timestamp()\n",
    "            currTime = clock.timestamp.replace(tzinfo=datetime.timezone.utc).timestamp()\n",
    "            timeToOpen = int((openingTime - currTime) / 60)\n",
    "            print(str(timeToOpen) + ' minutes till market open.')\n",
    "            time.sleep(60)\n",
    "            isOpen = self.alpaca.get_clock().is_open\n",
    "    \n",
    "    def testLatency(self, test_times = 10): \n",
    "        total_time = 0\n",
    "        for i in range(0, test_times):\n",
    "            time0 = time.time()\n",
    "            self.get_state()\n",
    "            time1 = time.time()\n",
    "            temp_time = time1 - time0\n",
    "            total_time += temp_time\n",
    "        latency = total_time/test_times\n",
    "        print('latency for data processing: ', latency)\n",
    "        return latency\n",
    "    \n",
    "    def submitOrder(self, qty, stock, side, resp):\n",
    "        if(qty > 0):\n",
    "            try:\n",
    "                self.alpaca.submit_order(str(stock), str(qty), side, \"market\", \"day\")\n",
    "                print(f\"Market order of | {str(qty)} {stock} {side} | Completed\")\n",
    "                resp.append(True)\n",
    "            except Exception as e:\n",
    "                print(f\"Market order of | {str(qty)} {stock} {side} | Failed\")\n",
    "                resp.append(False)\n",
    "                print(e)\n",
    "        else:\n",
    "            print(f\"Quantity is 0, order of | {str(qty)} {stock} {side} | Insufficient Quantity\")\n",
    "            resp.append(False)\n",
    "    \n",
    "    def sell_stock(self, action, index, state):\n",
    "        if state[index + 2 * self.account.stock_dimension + 1] != True:\n",
    "            if state[index + self.account.stock_dimension + 1] > 0:\n",
    "                sell_num_shares = min(\n",
    "                    int(abs(action)),  int(self.account.num_stock_shares[index])\n",
    "                )\n",
    "\n",
    "                respSO = []\n",
    "                tSubmitOrder = threading.Thread(\n",
    "                    target=self.submitOrder(\n",
    "                        sell_num_shares, # quantity\n",
    "                        self.account.ticker_list[index], # asset\n",
    "                        'sell', \n",
    "                        respSO\n",
    "                    )\n",
    "                )\n",
    "                tSubmitOrder.start()\n",
    "                tSubmitOrder.join()\n",
    "                if respSO[-1] == True:\n",
    "                    self.account.cash = float(self.alpaca.get_account().cash)\n",
    "                    if int(sell_num_shares) == int(self.account.num_stock_shares[index]):\n",
    "                        self.account.num_stock_shares[index] = 0\n",
    "                    else:\n",
    "                        self.account.num_stock_shares[index] -= sell_num_shares\n",
    "\n",
    "    def buy_stock(self, action, index, state):\n",
    "        if state[index + 2 * self.account.stock_dimension + 1] != True:\n",
    "            if float(self.alpaca.get_account().cash) > 0:\n",
    "\n",
    "                available_amount =  float(self.alpaca.get_account().cash) // (state[index + 1] * (1 + self.account.buy_cost_list[index]))\n",
    "                buy_num_shares = int(min(available_amount, action))\n",
    "\n",
    "                respSO = []\n",
    "                tSubmitOrder = threading.Thread(\n",
    "                    target=self.submitOrder(\n",
    "                        buy_num_shares, # quantity\n",
    "                        self.account.ticker_list[index], # asset\n",
    "                        'buy', \n",
    "                        respSO\n",
    "                    )\n",
    "                )\n",
    "                tSubmitOrder.start()\n",
    "                tSubmitOrder.join()\n",
    "\n",
    "                if respSO[-1] == True:\n",
    "                    self.account.cash = float(self.alpaca.get_account().cash)\n",
    "                    self.account.num_stock_shares[index] += buy_num_shares\n",
    "    \n",
    "    def get_state(self):\n",
    "        print(\"Creating state...\")\n",
    "        # get current data\n",
    "        data, turb = self.data_retrieve.download_live_data()\n",
    "        self.current_turbulence = turb\n",
    "\n",
    "        if self.pca_path == None:\n",
    "            ind_cols = data.loc[:, PCA_INDICATORS].columns\n",
    "        else:\n",
    "            ind_cols = list(range(0,self.data_retrieve.number_of_pca_comps))\n",
    "            # ind_cols.append(\"day\")\n",
    "            \n",
    "        state = (\n",
    "            [self.account.cash] # starting cash\n",
    "            + data.close.values.tolist() # all close prices\n",
    "            + self.account.num_stock_shares # number of assets owned per stock \n",
    "            + sum(\n",
    "                (\n",
    "                    data[tech].values.tolist()\n",
    "                    for tech in ind_cols\n",
    "                ),\n",
    "                [],\n",
    "            )\n",
    "        )\n",
    "        state = np.array([state])\n",
    "        state = state.astype('float64')\n",
    "        return state\n",
    "\n",
    "    def trade(self):\n",
    "        state = self.get_state()\n",
    "        action, _states = self.agent.predict(state, deterministic = True)\n",
    "        \n",
    "        action = action * self.account.hmax\n",
    "        action = action.astype(int) \n",
    "        print(action)\n",
    "        \n",
    "        if self.current_turbulence < self.turbulence_thresh:\n",
    "            argsort_actions = np.argsort(action[0])\n",
    "            sell_index = argsort_actions[: np.where(action < 0)[0].shape[0]]\n",
    "            buy_index = argsort_actions[::-1][: np.where(action > 0)[0].shape[0]]\n",
    "\n",
    "            for index in sell_index:\n",
    "                self.sell_stock(action[0][index], index, state[0])\n",
    "                time.sleep(5)\n",
    "            \n",
    "            for index in buy_index:\n",
    "                self.buy_stock(action[0][index], index, state[0])\n",
    "                time.sleep(5)\n",
    "            \n",
    "        else:\n",
    "            print(\"Turbulence is to high to trade ...\")\n",
    "            print(\"Skipping trading cycle\")\n",
    "\n",
    "    def select_new_alg(self):\n",
    "        # Agent\n",
    "        self.select_alg = regime_switching('2010-01-01', [\"a2c\", \"td3\", \"ddpg\", \"sac\", \"ppo\"], account_in = self.account)\n",
    "        self.agent = self.select_alg.run_regime_switching().model\n",
    "\n",
    "    def start(self):\n",
    "        # Ensure orders are clear\n",
    "        orders = self.alpaca.list_orders(status = \"open\")\n",
    "        for order in orders:\n",
    "            self.alpaca.cancel_order(order.id)\n",
    "        \n",
    "        # self.select_new_alg()\n",
    "        \n",
    "        # Awaiting Market Open\n",
    "        print(\"Waiting for market to open...\")\n",
    "        tAMO = threading.Thread(target=self.awaitMarketOpen) # setting function to a different thread so it can run in the background\n",
    "        tAMO.start()\n",
    "        tAMO.join()\n",
    "        print(\"Market Opened\") \n",
    "\n",
    "        while True:\n",
    "            # Market Closing time\n",
    "            clock = self.alpaca.get_clock()\n",
    "            closingTime = clock.next_close.replace(tzinfo=datetime.timezone.utc).timestamp()\n",
    "            currTime = clock.timestamp.replace(tzinfo=datetime.timezone.utc).timestamp()\n",
    "            self.timeToClose = closingTime - currTime\n",
    "\n",
    "            if self.timeToClose < (self.sell_time):\n",
    "                if self.sell_at_end_of_day == False:\n",
    "                    # Stop Trading\n",
    "                    print(f\"Market closing in {self.sell_time} seconds. Stopping Trading\")\n",
    "                    break\n",
    "\n",
    "                else:\n",
    "                    # Sell All\n",
    "                    print(f\"Market closing in {self.sell_time} seconds. Closing Positions\")\n",
    "\n",
    "                    positions = self.alpaca.list_positions()\n",
    "                    for position in positions:\n",
    "                        if position.side == 'long':\n",
    "                            orderSide = 'sell'\n",
    "                        else:\n",
    "                            orderSide = 'buy'\n",
    "                        \n",
    "                        qty = abs(int(float(position.qty)))\n",
    "                        respSO = []\n",
    "                        tSubmitOrder = threading.Thread(target=self.submitOrder(qty, position.symbol, orderSide, respSO))\n",
    "                        tSubmitOrder.start()\n",
    "                        tSubmitOrder.join()\n",
    "\n",
    "                    time.sleep(60 * 10)\n",
    "\n",
    "            else:\n",
    "                trade = threading.Thread(target=self.trade)\n",
    "                trade.start()\n",
    "                trade.join()\n",
    "                # last_equity = float(self.alpaca.get_account().last_equity)\n",
    "                # self.account.equities.append([time.time(), last_equity])\n",
    "                \n",
    "                time.sleep(120)\n",
    "                self.rebalance_counter += 1\n",
    "                if self.rebalance_counter == 63:\n",
    "                    self.rebalance_counter = 0\n",
    "                    self.select_new_alg()\n",
    "                self.account.cash = float(self.alpaca.get_account().cash)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_trader = AlpacaPaperTrading(ticker_list = DOW_30_TICKERS, \n",
    "                                  time_interval = TimeFrame.Day,\n",
    "                                  API_KEY = API_KEY, \n",
    "                                  API_SECRET = API_SECRET, \n",
    "                                  API_BASE_URL = API_BASE_URL, \n",
    "                                  tech_indicator_list = PCA_INDICATORS, \n",
    "                                  turbulence_thresh = 70, \n",
    "                                  latency = None,\n",
    "                                  pca_path = r\"D:\\University\\Thesis\\Multi Algorithm Soluction\\trained_models\\PCA_Model_0.9.pickle\"\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for market to open...\n",
      "4536 minutes till market open.\n",
      "4535 minutes till market open.\n"
     ]
    }
   ],
   "source": [
    "paper_trader.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-FinRL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "61866ea1f56d8d1253c5864ef53fda8c131f7a460e0c526de1cdeb101f9de6aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
